{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 12963,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003857131836766181,
      "grad_norm": 0.42000284790992737,
      "learning_rate": 0.00019924400215999384,
      "loss": 2.8044,
      "step": 50
    },
    {
      "epoch": 0.007714263673532362,
      "grad_norm": 0.49324455857276917,
      "learning_rate": 0.0001984725757926406,
      "loss": 2.4475,
      "step": 100
    },
    {
      "epoch": 0.011571395510298541,
      "grad_norm": 0.4867578446865082,
      "learning_rate": 0.00019770114942528738,
      "loss": 2.3849,
      "step": 150
    },
    {
      "epoch": 0.015428527347064723,
      "grad_norm": 0.5162601470947266,
      "learning_rate": 0.00019692972305793412,
      "loss": 2.346,
      "step": 200
    },
    {
      "epoch": 0.019285659183830902,
      "grad_norm": 0.5684319138526917,
      "learning_rate": 0.0001961582966905809,
      "loss": 2.37,
      "step": 250
    },
    {
      "epoch": 0.023142791020597082,
      "grad_norm": 0.6665070652961731,
      "learning_rate": 0.00019538687032322766,
      "loss": 2.3388,
      "step": 300
    },
    {
      "epoch": 0.026999922857363266,
      "grad_norm": 0.9403799772262573,
      "learning_rate": 0.0001946154439558744,
      "loss": 2.3248,
      "step": 350
    },
    {
      "epoch": 0.030857054694129447,
      "grad_norm": 0.632681667804718,
      "learning_rate": 0.00019384401758852117,
      "loss": 2.3019,
      "step": 400
    },
    {
      "epoch": 0.03471418653089563,
      "grad_norm": 0.590958833694458,
      "learning_rate": 0.00019307259122116794,
      "loss": 2.3053,
      "step": 450
    },
    {
      "epoch": 0.038571318367661804,
      "grad_norm": 0.6194835901260376,
      "learning_rate": 0.0001923011648538147,
      "loss": 2.278,
      "step": 500
    },
    {
      "epoch": 0.04242845020442799,
      "grad_norm": 0.6484672427177429,
      "learning_rate": 0.00019152973848646148,
      "loss": 2.2463,
      "step": 550
    },
    {
      "epoch": 0.046285582041194165,
      "grad_norm": 0.6205359101295471,
      "learning_rate": 0.00019075831211910825,
      "loss": 2.2537,
      "step": 600
    },
    {
      "epoch": 0.05014271387796035,
      "grad_norm": 0.6027677059173584,
      "learning_rate": 0.00018998688575175502,
      "loss": 2.2638,
      "step": 650
    },
    {
      "epoch": 0.05399984571472653,
      "grad_norm": 0.7129425406455994,
      "learning_rate": 0.00018921545938440179,
      "loss": 2.24,
      "step": 700
    },
    {
      "epoch": 0.05785697755149271,
      "grad_norm": 0.6319220066070557,
      "learning_rate": 0.00018844403301704853,
      "loss": 2.2285,
      "step": 750
    },
    {
      "epoch": 0.06171410938825889,
      "grad_norm": 0.6283077001571655,
      "learning_rate": 0.0001876726066496953,
      "loss": 2.2243,
      "step": 800
    },
    {
      "epoch": 0.06557124122502507,
      "grad_norm": 0.5669072270393372,
      "learning_rate": 0.00018690118028234207,
      "loss": 2.2108,
      "step": 850
    },
    {
      "epoch": 0.06942837306179125,
      "grad_norm": 0.668422520160675,
      "learning_rate": 0.0001861297539149888,
      "loss": 2.2345,
      "step": 900
    },
    {
      "epoch": 0.07328550489855744,
      "grad_norm": 0.671454668045044,
      "learning_rate": 0.00018535832754763558,
      "loss": 2.2144,
      "step": 950
    },
    {
      "epoch": 0.07714263673532361,
      "grad_norm": 0.6305563449859619,
      "learning_rate": 0.00018458690118028235,
      "loss": 2.2201,
      "step": 1000
    },
    {
      "epoch": 0.08099976857208979,
      "grad_norm": 0.6119972467422485,
      "learning_rate": 0.00018381547481292911,
      "loss": 2.2,
      "step": 1050
    },
    {
      "epoch": 0.08485690040885598,
      "grad_norm": 0.5847555994987488,
      "learning_rate": 0.00018304404844557588,
      "loss": 2.2158,
      "step": 1100
    },
    {
      "epoch": 0.08871403224562216,
      "grad_norm": 0.6640331745147705,
      "learning_rate": 0.00018227262207822265,
      "loss": 2.197,
      "step": 1150
    },
    {
      "epoch": 0.09257116408238833,
      "grad_norm": 0.6433481574058533,
      "learning_rate": 0.00018150119571086942,
      "loss": 2.1963,
      "step": 1200
    },
    {
      "epoch": 0.09642829591915451,
      "grad_norm": 0.6349763870239258,
      "learning_rate": 0.00018072976934351616,
      "loss": 2.2172,
      "step": 1250
    },
    {
      "epoch": 0.1002854277559207,
      "grad_norm": 0.580117404460907,
      "learning_rate": 0.00017995834297616293,
      "loss": 2.1983,
      "step": 1300
    },
    {
      "epoch": 0.10414255959268688,
      "grad_norm": 0.5811291337013245,
      "learning_rate": 0.0001791869166088097,
      "loss": 2.2041,
      "step": 1350
    },
    {
      "epoch": 0.10799969142945307,
      "grad_norm": 0.6261829733848572,
      "learning_rate": 0.00017841549024145644,
      "loss": 2.1865,
      "step": 1400
    },
    {
      "epoch": 0.11185682326621924,
      "grad_norm": 0.6340187788009644,
      "learning_rate": 0.0001776440638741032,
      "loss": 2.164,
      "step": 1450
    },
    {
      "epoch": 0.11571395510298542,
      "grad_norm": 0.5934545397758484,
      "learning_rate": 0.00017687263750674998,
      "loss": 2.1974,
      "step": 1500
    },
    {
      "epoch": 0.1195710869397516,
      "grad_norm": 0.6534910202026367,
      "learning_rate": 0.00017610121113939675,
      "loss": 2.1882,
      "step": 1550
    },
    {
      "epoch": 0.12342821877651779,
      "grad_norm": 0.6145511865615845,
      "learning_rate": 0.00017532978477204352,
      "loss": 2.2112,
      "step": 1600
    },
    {
      "epoch": 0.12728535061328397,
      "grad_norm": 0.6170051693916321,
      "learning_rate": 0.0001745583584046903,
      "loss": 2.1742,
      "step": 1650
    },
    {
      "epoch": 0.13114248245005014,
      "grad_norm": 0.6536855101585388,
      "learning_rate": 0.00017378693203733706,
      "loss": 2.2106,
      "step": 1700
    },
    {
      "epoch": 0.1349996142868163,
      "grad_norm": 0.6163774132728577,
      "learning_rate": 0.0001730155056699838,
      "loss": 2.1818,
      "step": 1750
    },
    {
      "epoch": 0.1388567461235825,
      "grad_norm": 0.6873055696487427,
      "learning_rate": 0.00017224407930263057,
      "loss": 2.1835,
      "step": 1800
    },
    {
      "epoch": 0.14271387796034868,
      "grad_norm": 0.659271776676178,
      "learning_rate": 0.00017147265293527734,
      "loss": 2.1808,
      "step": 1850
    },
    {
      "epoch": 0.14657100979711488,
      "grad_norm": 0.6127453446388245,
      "learning_rate": 0.0001707012265679241,
      "loss": 2.2008,
      "step": 1900
    },
    {
      "epoch": 0.15042814163388105,
      "grad_norm": 0.5882595777511597,
      "learning_rate": 0.00016992980020057085,
      "loss": 2.1884,
      "step": 1950
    },
    {
      "epoch": 0.15428527347064722,
      "grad_norm": 0.599030077457428,
      "learning_rate": 0.00016915837383321762,
      "loss": 2.2037,
      "step": 2000
    },
    {
      "epoch": 0.15814240530741341,
      "grad_norm": 0.6213117241859436,
      "learning_rate": 0.0001683869474658644,
      "loss": 2.1783,
      "step": 2050
    },
    {
      "epoch": 0.16199953714417958,
      "grad_norm": 0.6048707365989685,
      "learning_rate": 0.00016761552109851116,
      "loss": 2.1724,
      "step": 2100
    },
    {
      "epoch": 0.16585666898094578,
      "grad_norm": 0.6162206530570984,
      "learning_rate": 0.00016684409473115793,
      "loss": 2.1351,
      "step": 2150
    },
    {
      "epoch": 0.16971380081771195,
      "grad_norm": 0.6223341822624207,
      "learning_rate": 0.0001660726683638047,
      "loss": 2.1653,
      "step": 2200
    },
    {
      "epoch": 0.17357093265447812,
      "grad_norm": 0.5903985500335693,
      "learning_rate": 0.00016530124199645144,
      "loss": 2.181,
      "step": 2250
    },
    {
      "epoch": 0.17742806449124432,
      "grad_norm": 0.5876417756080627,
      "learning_rate": 0.0001645298156290982,
      "loss": 2.1572,
      "step": 2300
    },
    {
      "epoch": 0.1812851963280105,
      "grad_norm": 0.5656270384788513,
      "learning_rate": 0.00016375838926174498,
      "loss": 2.1528,
      "step": 2350
    },
    {
      "epoch": 0.18514232816477666,
      "grad_norm": 0.5621444582939148,
      "learning_rate": 0.00016298696289439174,
      "loss": 2.1543,
      "step": 2400
    },
    {
      "epoch": 0.18899946000154286,
      "grad_norm": 0.6216967105865479,
      "learning_rate": 0.00016221553652703849,
      "loss": 2.1495,
      "step": 2450
    },
    {
      "epoch": 0.19285659183830903,
      "grad_norm": 0.5806909799575806,
      "learning_rate": 0.00016144411015968526,
      "loss": 2.1592,
      "step": 2500
    },
    {
      "epoch": 0.19671372367507522,
      "grad_norm": 0.6228607296943665,
      "learning_rate": 0.00016067268379233202,
      "loss": 2.1541,
      "step": 2550
    },
    {
      "epoch": 0.2005708555118414,
      "grad_norm": 0.6998676061630249,
      "learning_rate": 0.0001599012574249788,
      "loss": 2.1602,
      "step": 2600
    },
    {
      "epoch": 0.20442798734860756,
      "grad_norm": 0.636093020439148,
      "learning_rate": 0.00015912983105762556,
      "loss": 2.1513,
      "step": 2650
    },
    {
      "epoch": 0.20828511918537376,
      "grad_norm": 0.7109109163284302,
      "learning_rate": 0.00015835840469027233,
      "loss": 2.1669,
      "step": 2700
    },
    {
      "epoch": 0.21214225102213993,
      "grad_norm": 0.5791848301887512,
      "learning_rate": 0.0001575869783229191,
      "loss": 2.1677,
      "step": 2750
    },
    {
      "epoch": 0.21599938285890613,
      "grad_norm": 0.5807026624679565,
      "learning_rate": 0.00015681555195556584,
      "loss": 2.1564,
      "step": 2800
    },
    {
      "epoch": 0.2198565146956723,
      "grad_norm": 0.6728065609931946,
      "learning_rate": 0.0001560441255882126,
      "loss": 2.1716,
      "step": 2850
    },
    {
      "epoch": 0.22371364653243847,
      "grad_norm": 0.5928393006324768,
      "learning_rate": 0.00015527269922085938,
      "loss": 2.1293,
      "step": 2900
    },
    {
      "epoch": 0.22757077836920467,
      "grad_norm": 0.5517435073852539,
      "learning_rate": 0.00015450127285350612,
      "loss": 2.1443,
      "step": 2950
    },
    {
      "epoch": 0.23142791020597084,
      "grad_norm": 0.6044371724128723,
      "learning_rate": 0.0001537298464861529,
      "loss": 2.146,
      "step": 3000
    },
    {
      "epoch": 0.235285042042737,
      "grad_norm": 0.6431764960289001,
      "learning_rate": 0.00015295842011879966,
      "loss": 2.1388,
      "step": 3050
    },
    {
      "epoch": 0.2391421738795032,
      "grad_norm": 0.6247325539588928,
      "learning_rate": 0.00015218699375144643,
      "loss": 2.1483,
      "step": 3100
    },
    {
      "epoch": 0.24299930571626938,
      "grad_norm": 0.5941407084465027,
      "learning_rate": 0.0001514155673840932,
      "loss": 2.1457,
      "step": 3150
    },
    {
      "epoch": 0.24685643755303557,
      "grad_norm": 0.5893806219100952,
      "learning_rate": 0.00015064414101673997,
      "loss": 2.1404,
      "step": 3200
    },
    {
      "epoch": 0.2507135693898017,
      "grad_norm": 0.5804574489593506,
      "learning_rate": 0.00014987271464938674,
      "loss": 2.1321,
      "step": 3250
    },
    {
      "epoch": 0.25457070122656794,
      "grad_norm": 0.5954149961471558,
      "learning_rate": 0.00014910128828203348,
      "loss": 2.1255,
      "step": 3300
    },
    {
      "epoch": 0.2584278330633341,
      "grad_norm": 0.5911341905593872,
      "learning_rate": 0.00014832986191468025,
      "loss": 2.146,
      "step": 3350
    },
    {
      "epoch": 0.2622849649001003,
      "grad_norm": 0.5748605728149414,
      "learning_rate": 0.00014755843554732702,
      "loss": 2.1193,
      "step": 3400
    },
    {
      "epoch": 0.26614209673686645,
      "grad_norm": 0.5422318577766418,
      "learning_rate": 0.0001467870091799738,
      "loss": 2.1083,
      "step": 3450
    },
    {
      "epoch": 0.2699992285736326,
      "grad_norm": 0.5776340365409851,
      "learning_rate": 0.00014601558281262053,
      "loss": 2.1274,
      "step": 3500
    },
    {
      "epoch": 0.27385636041039885,
      "grad_norm": 0.6042219400405884,
      "learning_rate": 0.0001452441564452673,
      "loss": 2.1555,
      "step": 3550
    },
    {
      "epoch": 0.277713492247165,
      "grad_norm": 0.5663055181503296,
      "learning_rate": 0.00014447273007791407,
      "loss": 2.1563,
      "step": 3600
    },
    {
      "epoch": 0.2815706240839312,
      "grad_norm": 0.6329196691513062,
      "learning_rate": 0.00014370130371056084,
      "loss": 2.134,
      "step": 3650
    },
    {
      "epoch": 0.28542775592069736,
      "grad_norm": 0.6533851027488708,
      "learning_rate": 0.0001429298773432076,
      "loss": 2.1282,
      "step": 3700
    },
    {
      "epoch": 0.2892848877574635,
      "grad_norm": 0.6167345643043518,
      "learning_rate": 0.00014215845097585437,
      "loss": 2.1343,
      "step": 3750
    },
    {
      "epoch": 0.29314201959422975,
      "grad_norm": 0.5595912933349609,
      "learning_rate": 0.00014138702460850112,
      "loss": 2.1203,
      "step": 3800
    },
    {
      "epoch": 0.2969991514309959,
      "grad_norm": 0.5656962394714355,
      "learning_rate": 0.00014061559824114789,
      "loss": 2.1355,
      "step": 3850
    },
    {
      "epoch": 0.3008562832677621,
      "grad_norm": 0.6240189075469971,
      "learning_rate": 0.00013984417187379465,
      "loss": 2.1217,
      "step": 3900
    },
    {
      "epoch": 0.30471341510452826,
      "grad_norm": 0.6388822197914124,
      "learning_rate": 0.00013907274550644142,
      "loss": 2.1294,
      "step": 3950
    },
    {
      "epoch": 0.30857054694129443,
      "grad_norm": 0.7781481146812439,
      "learning_rate": 0.00013830131913908817,
      "loss": 2.1324,
      "step": 4000
    },
    {
      "epoch": 0.31242767877806066,
      "grad_norm": 0.5933670401573181,
      "learning_rate": 0.00013752989277173493,
      "loss": 2.1187,
      "step": 4050
    },
    {
      "epoch": 0.31628481061482683,
      "grad_norm": 0.6355007290840149,
      "learning_rate": 0.0001367584664043817,
      "loss": 2.1377,
      "step": 4100
    },
    {
      "epoch": 0.320141942451593,
      "grad_norm": 0.5851848125457764,
      "learning_rate": 0.00013598704003702847,
      "loss": 2.1261,
      "step": 4150
    },
    {
      "epoch": 0.32399907428835917,
      "grad_norm": 0.5778322219848633,
      "learning_rate": 0.00013521561366967524,
      "loss": 2.1333,
      "step": 4200
    },
    {
      "epoch": 0.32785620612512534,
      "grad_norm": 0.5529745221138,
      "learning_rate": 0.000134444187302322,
      "loss": 2.121,
      "step": 4250
    },
    {
      "epoch": 0.33171333796189156,
      "grad_norm": 0.579740583896637,
      "learning_rate": 0.00013367276093496875,
      "loss": 2.1183,
      "step": 4300
    },
    {
      "epoch": 0.33557046979865773,
      "grad_norm": 0.6616054177284241,
      "learning_rate": 0.00013290133456761552,
      "loss": 2.1547,
      "step": 4350
    },
    {
      "epoch": 0.3394276016354239,
      "grad_norm": 0.6257096529006958,
      "learning_rate": 0.0001321299082002623,
      "loss": 2.1526,
      "step": 4400
    },
    {
      "epoch": 0.3432847334721901,
      "grad_norm": 0.6109728813171387,
      "learning_rate": 0.00013135848183290906,
      "loss": 2.162,
      "step": 4450
    },
    {
      "epoch": 0.34714186530895624,
      "grad_norm": 0.5468094944953918,
      "learning_rate": 0.00013058705546555583,
      "loss": 2.1204,
      "step": 4500
    },
    {
      "epoch": 0.3509989971457224,
      "grad_norm": 0.5543652772903442,
      "learning_rate": 0.00012981562909820257,
      "loss": 2.1192,
      "step": 4550
    },
    {
      "epoch": 0.35485612898248864,
      "grad_norm": 0.5408369898796082,
      "learning_rate": 0.00012904420273084934,
      "loss": 2.116,
      "step": 4600
    },
    {
      "epoch": 0.3587132608192548,
      "grad_norm": 0.5967521071434021,
      "learning_rate": 0.0001282727763634961,
      "loss": 2.1126,
      "step": 4650
    },
    {
      "epoch": 0.362570392656021,
      "grad_norm": 0.5995936989784241,
      "learning_rate": 0.00012750134999614288,
      "loss": 2.1277,
      "step": 4700
    },
    {
      "epoch": 0.36642752449278715,
      "grad_norm": 0.640364944934845,
      "learning_rate": 0.00012672992362878965,
      "loss": 2.1048,
      "step": 4750
    },
    {
      "epoch": 0.3702846563295533,
      "grad_norm": 0.6152336597442627,
      "learning_rate": 0.00012595849726143642,
      "loss": 2.1328,
      "step": 4800
    },
    {
      "epoch": 0.37414178816631954,
      "grad_norm": 0.6068558096885681,
      "learning_rate": 0.00012518707089408316,
      "loss": 2.0928,
      "step": 4850
    },
    {
      "epoch": 0.3779989200030857,
      "grad_norm": 0.5813338160514832,
      "learning_rate": 0.00012441564452672993,
      "loss": 2.1075,
      "step": 4900
    },
    {
      "epoch": 0.3818560518398519,
      "grad_norm": 0.5754809379577637,
      "learning_rate": 0.0001236442181593767,
      "loss": 2.1367,
      "step": 4950
    },
    {
      "epoch": 0.38571318367661805,
      "grad_norm": 0.548975944519043,
      "learning_rate": 0.00012287279179202347,
      "loss": 2.0944,
      "step": 5000
    },
    {
      "epoch": 0.3895703155133842,
      "grad_norm": 0.5801439881324768,
      "learning_rate": 0.0001221013654246702,
      "loss": 2.1227,
      "step": 5050
    },
    {
      "epoch": 0.39342744735015045,
      "grad_norm": 0.5463036894798279,
      "learning_rate": 0.00012132993905731698,
      "loss": 2.1276,
      "step": 5100
    },
    {
      "epoch": 0.3972845791869166,
      "grad_norm": 0.570537269115448,
      "learning_rate": 0.00012055851268996375,
      "loss": 2.1084,
      "step": 5150
    },
    {
      "epoch": 0.4011417110236828,
      "grad_norm": 0.586781919002533,
      "learning_rate": 0.00011978708632261051,
      "loss": 2.1218,
      "step": 5200
    },
    {
      "epoch": 0.40499884286044896,
      "grad_norm": 0.550102949142456,
      "learning_rate": 0.00011901565995525727,
      "loss": 2.1179,
      "step": 5250
    },
    {
      "epoch": 0.40885597469721513,
      "grad_norm": 0.5542900562286377,
      "learning_rate": 0.00011824423358790404,
      "loss": 2.1451,
      "step": 5300
    },
    {
      "epoch": 0.41271310653398136,
      "grad_norm": 0.5663469433784485,
      "learning_rate": 0.00011747280722055081,
      "loss": 2.1202,
      "step": 5350
    },
    {
      "epoch": 0.4165702383707475,
      "grad_norm": 0.7925407886505127,
      "learning_rate": 0.00011670138085319758,
      "loss": 2.1142,
      "step": 5400
    },
    {
      "epoch": 0.4204273702075137,
      "grad_norm": 0.5766502022743225,
      "learning_rate": 0.00011592995448584433,
      "loss": 2.1065,
      "step": 5450
    },
    {
      "epoch": 0.42428450204427987,
      "grad_norm": 0.5938941836357117,
      "learning_rate": 0.0001151585281184911,
      "loss": 2.1357,
      "step": 5500
    },
    {
      "epoch": 0.42814163388104604,
      "grad_norm": 0.6184863448143005,
      "learning_rate": 0.00011438710175113784,
      "loss": 2.1158,
      "step": 5550
    },
    {
      "epoch": 0.43199876571781226,
      "grad_norm": 0.7312973737716675,
      "learning_rate": 0.00011361567538378461,
      "loss": 2.1296,
      "step": 5600
    },
    {
      "epoch": 0.43585589755457843,
      "grad_norm": 0.5992135405540466,
      "learning_rate": 0.00011284424901643138,
      "loss": 2.1201,
      "step": 5650
    },
    {
      "epoch": 0.4397130293913446,
      "grad_norm": 0.5398194789886475,
      "learning_rate": 0.00011207282264907815,
      "loss": 2.1277,
      "step": 5700
    },
    {
      "epoch": 0.44357016122811077,
      "grad_norm": 0.5695991516113281,
      "learning_rate": 0.00011130139628172491,
      "loss": 2.1131,
      "step": 5750
    },
    {
      "epoch": 0.44742729306487694,
      "grad_norm": 0.5871589183807373,
      "learning_rate": 0.00011052996991437168,
      "loss": 2.1347,
      "step": 5800
    },
    {
      "epoch": 0.4512844249016431,
      "grad_norm": 0.5422275066375732,
      "learning_rate": 0.00010975854354701845,
      "loss": 2.1209,
      "step": 5850
    },
    {
      "epoch": 0.45514155673840934,
      "grad_norm": 0.6024190783500671,
      "learning_rate": 0.00010898711717966521,
      "loss": 2.1114,
      "step": 5900
    },
    {
      "epoch": 0.4589986885751755,
      "grad_norm": 0.5755265951156616,
      "learning_rate": 0.00010821569081231197,
      "loss": 2.1227,
      "step": 5950
    },
    {
      "epoch": 0.4628558204119417,
      "grad_norm": 0.5278096795082092,
      "learning_rate": 0.00010744426444495874,
      "loss": 2.12,
      "step": 6000
    },
    {
      "epoch": 0.46671295224870785,
      "grad_norm": 0.6329576969146729,
      "learning_rate": 0.00010668826660495257,
      "loss": 2.1238,
      "step": 6050
    },
    {
      "epoch": 0.470570084085474,
      "grad_norm": 0.7120281457901001,
      "learning_rate": 0.00010591684023759934,
      "loss": 2.1308,
      "step": 6100
    },
    {
      "epoch": 0.47442721592224024,
      "grad_norm": 0.7025847434997559,
      "learning_rate": 0.0001051454138702461,
      "loss": 2.1156,
      "step": 6150
    },
    {
      "epoch": 0.4782843477590064,
      "grad_norm": 0.6125283241271973,
      "learning_rate": 0.00010437398750289285,
      "loss": 2.096,
      "step": 6200
    },
    {
      "epoch": 0.4821414795957726,
      "grad_norm": 0.6454260349273682,
      "learning_rate": 0.0001036025611355396,
      "loss": 2.1186,
      "step": 6250
    },
    {
      "epoch": 0.48599861143253875,
      "grad_norm": 0.6115254759788513,
      "learning_rate": 0.00010283113476818638,
      "loss": 2.1228,
      "step": 6300
    },
    {
      "epoch": 0.4898557432693049,
      "grad_norm": 0.6556738615036011,
      "learning_rate": 0.00010205970840083314,
      "loss": 2.0961,
      "step": 6350
    },
    {
      "epoch": 0.49371287510607115,
      "grad_norm": 0.5835193395614624,
      "learning_rate": 0.00010128828203347991,
      "loss": 2.1057,
      "step": 6400
    },
    {
      "epoch": 0.4975700069428373,
      "grad_norm": 0.5668113827705383,
      "learning_rate": 0.00010051685566612667,
      "loss": 2.1238,
      "step": 6450
    },
    {
      "epoch": 0.5014271387796034,
      "grad_norm": 0.6317726373672485,
      "learning_rate": 9.974542929877344e-05,
      "loss": 2.1228,
      "step": 6500
    },
    {
      "epoch": 0.5052842706163697,
      "grad_norm": 0.628154993057251,
      "learning_rate": 9.89740029314202e-05,
      "loss": 2.1304,
      "step": 6550
    },
    {
      "epoch": 0.5091414024531359,
      "grad_norm": 0.6206783056259155,
      "learning_rate": 9.820257656406696e-05,
      "loss": 2.116,
      "step": 6600
    },
    {
      "epoch": 0.512998534289902,
      "grad_norm": 0.5850354433059692,
      "learning_rate": 9.743115019671373e-05,
      "loss": 2.0956,
      "step": 6650
    },
    {
      "epoch": 0.5168556661266682,
      "grad_norm": 0.6027910113334656,
      "learning_rate": 9.665972382936049e-05,
      "loss": 2.1143,
      "step": 6700
    },
    {
      "epoch": 0.5207127979634344,
      "grad_norm": 0.677678108215332,
      "learning_rate": 9.588829746200726e-05,
      "loss": 2.1163,
      "step": 6750
    },
    {
      "epoch": 0.5245699298002006,
      "grad_norm": 0.646862268447876,
      "learning_rate": 9.511687109465403e-05,
      "loss": 2.0979,
      "step": 6800
    },
    {
      "epoch": 0.5284270616369667,
      "grad_norm": 0.5784755945205688,
      "learning_rate": 9.434544472730078e-05,
      "loss": 2.0956,
      "step": 6850
    },
    {
      "epoch": 0.5322841934737329,
      "grad_norm": 0.6468380093574524,
      "learning_rate": 9.357401835994755e-05,
      "loss": 2.0918,
      "step": 6900
    },
    {
      "epoch": 0.5361413253104991,
      "grad_norm": 0.6567462682723999,
      "learning_rate": 9.28025919925943e-05,
      "loss": 2.1146,
      "step": 6950
    },
    {
      "epoch": 0.5399984571472652,
      "grad_norm": 0.5676478147506714,
      "learning_rate": 9.203116562524107e-05,
      "loss": 2.0801,
      "step": 7000
    },
    {
      "epoch": 0.5438555889840315,
      "grad_norm": 0.6272212862968445,
      "learning_rate": 9.125973925788784e-05,
      "loss": 2.125,
      "step": 7050
    },
    {
      "epoch": 0.5477127208207977,
      "grad_norm": 0.6261080503463745,
      "learning_rate": 9.04883128905346e-05,
      "loss": 2.1185,
      "step": 7100
    },
    {
      "epoch": 0.5515698526575639,
      "grad_norm": 0.6328652501106262,
      "learning_rate": 8.971688652318137e-05,
      "loss": 2.1199,
      "step": 7150
    },
    {
      "epoch": 0.55542698449433,
      "grad_norm": 0.5861806273460388,
      "learning_rate": 8.894546015582812e-05,
      "loss": 2.1118,
      "step": 7200
    },
    {
      "epoch": 0.5592841163310962,
      "grad_norm": 0.528366208076477,
      "learning_rate": 8.817403378847489e-05,
      "loss": 2.1182,
      "step": 7250
    },
    {
      "epoch": 0.5631412481678624,
      "grad_norm": 0.6184604167938232,
      "learning_rate": 8.740260742112166e-05,
      "loss": 2.1292,
      "step": 7300
    },
    {
      "epoch": 0.5669983800046285,
      "grad_norm": 0.5877507925033569,
      "learning_rate": 8.663118105376842e-05,
      "loss": 2.1155,
      "step": 7350
    },
    {
      "epoch": 0.5708555118413947,
      "grad_norm": 0.7298998832702637,
      "learning_rate": 8.585975468641519e-05,
      "loss": 2.1142,
      "step": 7400
    },
    {
      "epoch": 0.5747126436781609,
      "grad_norm": 0.6039174199104309,
      "learning_rate": 8.508832831906196e-05,
      "loss": 2.0964,
      "step": 7450
    },
    {
      "epoch": 0.578569775514927,
      "grad_norm": 0.5721714496612549,
      "learning_rate": 8.431690195170871e-05,
      "loss": 2.1141,
      "step": 7500
    },
    {
      "epoch": 0.5824269073516933,
      "grad_norm": 0.5803995132446289,
      "learning_rate": 8.354547558435548e-05,
      "loss": 2.0975,
      "step": 7550
    },
    {
      "epoch": 0.5862840391884595,
      "grad_norm": 0.547936201095581,
      "learning_rate": 8.277404921700224e-05,
      "loss": 2.0804,
      "step": 7600
    },
    {
      "epoch": 0.5901411710252257,
      "grad_norm": 0.6531224250793457,
      "learning_rate": 8.2002622849649e-05,
      "loss": 2.1031,
      "step": 7650
    },
    {
      "epoch": 0.5939983028619918,
      "grad_norm": 0.6070482134819031,
      "learning_rate": 8.123119648229577e-05,
      "loss": 2.102,
      "step": 7700
    },
    {
      "epoch": 0.597855434698758,
      "grad_norm": 0.7131936550140381,
      "learning_rate": 8.045977011494253e-05,
      "loss": 2.0873,
      "step": 7750
    },
    {
      "epoch": 0.6017125665355242,
      "grad_norm": 0.6040233373641968,
      "learning_rate": 7.96883437475893e-05,
      "loss": 2.1106,
      "step": 7800
    },
    {
      "epoch": 0.6055696983722904,
      "grad_norm": 0.5746901035308838,
      "learning_rate": 7.891691738023605e-05,
      "loss": 2.0842,
      "step": 7850
    },
    {
      "epoch": 0.6094268302090565,
      "grad_norm": 0.6410928964614868,
      "learning_rate": 7.814549101288282e-05,
      "loss": 2.0986,
      "step": 7900
    },
    {
      "epoch": 0.6132839620458227,
      "grad_norm": 0.6211259365081787,
      "learning_rate": 7.737406464552959e-05,
      "loss": 2.1042,
      "step": 7950
    },
    {
      "epoch": 0.6171410938825889,
      "grad_norm": 0.6268085241317749,
      "learning_rate": 7.660263827817635e-05,
      "loss": 2.0811,
      "step": 8000
    },
    {
      "epoch": 0.620998225719355,
      "grad_norm": 0.6609276533126831,
      "learning_rate": 7.583121191082312e-05,
      "loss": 2.1157,
      "step": 8050
    },
    {
      "epoch": 0.6248553575561213,
      "grad_norm": 0.6368469595909119,
      "learning_rate": 7.505978554346989e-05,
      "loss": 2.079,
      "step": 8100
    },
    {
      "epoch": 0.6287124893928875,
      "grad_norm": 0.595583975315094,
      "learning_rate": 7.428835917611664e-05,
      "loss": 2.1054,
      "step": 8150
    },
    {
      "epoch": 0.6325696212296537,
      "grad_norm": 0.5955994129180908,
      "learning_rate": 7.351693280876341e-05,
      "loss": 2.1278,
      "step": 8200
    },
    {
      "epoch": 0.6364267530664198,
      "grad_norm": 0.6420083045959473,
      "learning_rate": 7.274550644141017e-05,
      "loss": 2.0855,
      "step": 8250
    },
    {
      "epoch": 0.640283884903186,
      "grad_norm": 0.623378336429596,
      "learning_rate": 7.197408007405694e-05,
      "loss": 2.1041,
      "step": 8300
    },
    {
      "epoch": 0.6441410167399522,
      "grad_norm": 0.5949868559837341,
      "learning_rate": 7.12026537067037e-05,
      "loss": 2.0944,
      "step": 8350
    },
    {
      "epoch": 0.6479981485767183,
      "grad_norm": 0.6739025712013245,
      "learning_rate": 7.043122733935046e-05,
      "loss": 2.0875,
      "step": 8400
    },
    {
      "epoch": 0.6518552804134845,
      "grad_norm": 0.6131958365440369,
      "learning_rate": 6.965980097199723e-05,
      "loss": 2.0857,
      "step": 8450
    },
    {
      "epoch": 0.6557124122502507,
      "grad_norm": 0.6040792465209961,
      "learning_rate": 6.888837460464398e-05,
      "loss": 2.0891,
      "step": 8500
    },
    {
      "epoch": 0.6595695440870168,
      "grad_norm": 0.5980754494667053,
      "learning_rate": 6.811694823729075e-05,
      "loss": 2.0984,
      "step": 8550
    },
    {
      "epoch": 0.6634266759237831,
      "grad_norm": 0.5713339447975159,
      "learning_rate": 6.734552186993752e-05,
      "loss": 2.1107,
      "step": 8600
    },
    {
      "epoch": 0.6672838077605493,
      "grad_norm": 0.5905284285545349,
      "learning_rate": 6.657409550258428e-05,
      "loss": 2.0716,
      "step": 8650
    },
    {
      "epoch": 0.6711409395973155,
      "grad_norm": 0.6621080636978149,
      "learning_rate": 6.580266913523105e-05,
      "loss": 2.0831,
      "step": 8700
    },
    {
      "epoch": 0.6749980714340816,
      "grad_norm": 0.659134566783905,
      "learning_rate": 6.50312427678778e-05,
      "loss": 2.0997,
      "step": 8750
    },
    {
      "epoch": 0.6788552032708478,
      "grad_norm": 0.5833812952041626,
      "learning_rate": 6.425981640052457e-05,
      "loss": 2.0918,
      "step": 8800
    },
    {
      "epoch": 0.682712335107614,
      "grad_norm": 0.6704684495925903,
      "learning_rate": 6.348839003317134e-05,
      "loss": 2.1133,
      "step": 8850
    },
    {
      "epoch": 0.6865694669443801,
      "grad_norm": 0.5690057277679443,
      "learning_rate": 6.27169636658181e-05,
      "loss": 2.1133,
      "step": 8900
    },
    {
      "epoch": 0.6904265987811463,
      "grad_norm": 0.6051116585731506,
      "learning_rate": 6.194553729846487e-05,
      "loss": 2.0878,
      "step": 8950
    },
    {
      "epoch": 0.6942837306179125,
      "grad_norm": 0.6692200303077698,
      "learning_rate": 6.117411093111162e-05,
      "loss": 2.0876,
      "step": 9000
    },
    {
      "epoch": 0.6981408624546787,
      "grad_norm": 0.6314975619316101,
      "learning_rate": 6.041811309110545e-05,
      "loss": 2.0729,
      "step": 9050
    },
    {
      "epoch": 0.7019979942914448,
      "grad_norm": 0.713114857673645,
      "learning_rate": 5.964668672375222e-05,
      "loss": 2.1009,
      "step": 9100
    },
    {
      "epoch": 0.7058551261282111,
      "grad_norm": 0.604238748550415,
      "learning_rate": 5.8875260356398985e-05,
      "loss": 2.1028,
      "step": 9150
    },
    {
      "epoch": 0.7097122579649773,
      "grad_norm": 0.5837484002113342,
      "learning_rate": 5.8103833989045754e-05,
      "loss": 2.1099,
      "step": 9200
    },
    {
      "epoch": 0.7135693898017434,
      "grad_norm": 0.6356065273284912,
      "learning_rate": 5.733240762169251e-05,
      "loss": 2.1013,
      "step": 9250
    },
    {
      "epoch": 0.7174265216385096,
      "grad_norm": 0.6151502728462219,
      "learning_rate": 5.656098125433927e-05,
      "loss": 2.1029,
      "step": 9300
    },
    {
      "epoch": 0.7212836534752758,
      "grad_norm": 0.5850796699523926,
      "learning_rate": 5.578955488698604e-05,
      "loss": 2.1144,
      "step": 9350
    },
    {
      "epoch": 0.725140785312042,
      "grad_norm": 0.5836374163627625,
      "learning_rate": 5.50181285196328e-05,
      "loss": 2.0755,
      "step": 9400
    },
    {
      "epoch": 0.7289979171488081,
      "grad_norm": 0.6510493755340576,
      "learning_rate": 5.424670215227957e-05,
      "loss": 2.0936,
      "step": 9450
    },
    {
      "epoch": 0.7328550489855743,
      "grad_norm": 0.64017254114151,
      "learning_rate": 5.347527578492633e-05,
      "loss": 2.1018,
      "step": 9500
    },
    {
      "epoch": 0.7367121808223405,
      "grad_norm": 0.6070563197135925,
      "learning_rate": 5.270384941757309e-05,
      "loss": 2.0857,
      "step": 9550
    },
    {
      "epoch": 0.7405693126591066,
      "grad_norm": 0.6677919626235962,
      "learning_rate": 5.193242305021986e-05,
      "loss": 2.0867,
      "step": 9600
    },
    {
      "epoch": 0.7444264444958729,
      "grad_norm": 0.5644751787185669,
      "learning_rate": 5.116099668286662e-05,
      "loss": 2.089,
      "step": 9650
    },
    {
      "epoch": 0.7482835763326391,
      "grad_norm": 0.6246574521064758,
      "learning_rate": 5.038957031551339e-05,
      "loss": 2.0693,
      "step": 9700
    },
    {
      "epoch": 0.7521407081694053,
      "grad_norm": 0.658240556716919,
      "learning_rate": 4.961814394816015e-05,
      "loss": 2.0791,
      "step": 9750
    },
    {
      "epoch": 0.7559978400061714,
      "grad_norm": 0.5818688273429871,
      "learning_rate": 4.8846717580806915e-05,
      "loss": 2.1076,
      "step": 9800
    },
    {
      "epoch": 0.7598549718429376,
      "grad_norm": 0.6433318853378296,
      "learning_rate": 4.807529121345368e-05,
      "loss": 2.0898,
      "step": 9850
    },
    {
      "epoch": 0.7637121036797038,
      "grad_norm": 0.5644131302833557,
      "learning_rate": 4.7303864846100446e-05,
      "loss": 2.113,
      "step": 9900
    },
    {
      "epoch": 0.7675692355164699,
      "grad_norm": 0.5390835404396057,
      "learning_rate": 4.65324384787472e-05,
      "loss": 2.0927,
      "step": 9950
    },
    {
      "epoch": 0.7714263673532361,
      "grad_norm": 0.6144297122955322,
      "learning_rate": 4.576101211139397e-05,
      "loss": 2.0891,
      "step": 10000
    },
    {
      "epoch": 0.7752834991900023,
      "grad_norm": 0.6247192025184631,
      "learning_rate": 4.498958574404073e-05,
      "loss": 2.0839,
      "step": 10050
    },
    {
      "epoch": 0.7791406310267684,
      "grad_norm": 0.6594304442405701,
      "learning_rate": 4.4218159376687496e-05,
      "loss": 2.1221,
      "step": 10100
    },
    {
      "epoch": 0.7829977628635347,
      "grad_norm": 0.7353848814964294,
      "learning_rate": 4.3446733009334265e-05,
      "loss": 2.1143,
      "step": 10150
    },
    {
      "epoch": 0.7868548947003009,
      "grad_norm": 0.6277968883514404,
      "learning_rate": 4.267530664198103e-05,
      "loss": 2.0925,
      "step": 10200
    },
    {
      "epoch": 0.7907120265370671,
      "grad_norm": 0.5985845327377319,
      "learning_rate": 4.190388027462779e-05,
      "loss": 2.1022,
      "step": 10250
    },
    {
      "epoch": 0.7945691583738332,
      "grad_norm": 0.617145299911499,
      "learning_rate": 4.113245390727455e-05,
      "loss": 2.0865,
      "step": 10300
    },
    {
      "epoch": 0.7984262902105994,
      "grad_norm": 0.6553586721420288,
      "learning_rate": 4.0361027539921314e-05,
      "loss": 2.0877,
      "step": 10350
    },
    {
      "epoch": 0.8022834220473656,
      "grad_norm": 0.6236574649810791,
      "learning_rate": 3.958960117256808e-05,
      "loss": 2.086,
      "step": 10400
    },
    {
      "epoch": 0.8061405538841317,
      "grad_norm": 0.6738993525505066,
      "learning_rate": 3.8818174805214845e-05,
      "loss": 2.0688,
      "step": 10450
    },
    {
      "epoch": 0.8099976857208979,
      "grad_norm": 0.6409392356872559,
      "learning_rate": 3.804674843786161e-05,
      "loss": 2.0732,
      "step": 10500
    },
    {
      "epoch": 0.8138548175576641,
      "grad_norm": 0.6110963225364685,
      "learning_rate": 3.727532207050837e-05,
      "loss": 2.0802,
      "step": 10550
    },
    {
      "epoch": 0.8177119493944303,
      "grad_norm": 0.6078874468803406,
      "learning_rate": 3.650389570315513e-05,
      "loss": 2.0692,
      "step": 10600
    },
    {
      "epoch": 0.8215690812311964,
      "grad_norm": 0.6079971790313721,
      "learning_rate": 3.57324693358019e-05,
      "loss": 2.0842,
      "step": 10650
    },
    {
      "epoch": 0.8254262130679627,
      "grad_norm": 0.6224395036697388,
      "learning_rate": 3.4961042968448664e-05,
      "loss": 2.0603,
      "step": 10700
    },
    {
      "epoch": 0.8292833449047289,
      "grad_norm": 0.6469742655754089,
      "learning_rate": 3.4189616601095426e-05,
      "loss": 2.0828,
      "step": 10750
    },
    {
      "epoch": 0.833140476741495,
      "grad_norm": 0.5672374367713928,
      "learning_rate": 3.341819023374219e-05,
      "loss": 2.1191,
      "step": 10800
    },
    {
      "epoch": 0.8369976085782612,
      "grad_norm": 0.6896845102310181,
      "learning_rate": 3.264676386638896e-05,
      "loss": 2.0759,
      "step": 10850
    },
    {
      "epoch": 0.8408547404150274,
      "grad_norm": 0.5773475766181946,
      "learning_rate": 3.187533749903572e-05,
      "loss": 2.0918,
      "step": 10900
    },
    {
      "epoch": 0.8447118722517936,
      "grad_norm": 0.5596258640289307,
      "learning_rate": 3.110391113168248e-05,
      "loss": 2.1121,
      "step": 10950
    },
    {
      "epoch": 0.8485690040885597,
      "grad_norm": 0.5444100499153137,
      "learning_rate": 3.0332484764329244e-05,
      "loss": 2.0707,
      "step": 11000
    },
    {
      "epoch": 0.8524261359253259,
      "grad_norm": 0.7468343377113342,
      "learning_rate": 2.956105839697601e-05,
      "loss": 2.0933,
      "step": 11050
    },
    {
      "epoch": 0.8562832677620921,
      "grad_norm": 0.5895608067512512,
      "learning_rate": 2.8789632029622776e-05,
      "loss": 2.0945,
      "step": 11100
    },
    {
      "epoch": 0.8601403995988582,
      "grad_norm": 0.5803613662719727,
      "learning_rate": 2.8018205662269538e-05,
      "loss": 2.0691,
      "step": 11150
    },
    {
      "epoch": 0.8639975314356245,
      "grad_norm": 0.5869931578636169,
      "learning_rate": 2.7246779294916304e-05,
      "loss": 2.0931,
      "step": 11200
    },
    {
      "epoch": 0.8678546632723907,
      "grad_norm": 0.6111325025558472,
      "learning_rate": 2.6475352927563062e-05,
      "loss": 2.0819,
      "step": 11250
    },
    {
      "epoch": 0.8717117951091569,
      "grad_norm": 0.6046026945114136,
      "learning_rate": 2.5703926560209828e-05,
      "loss": 2.0971,
      "step": 11300
    },
    {
      "epoch": 0.875568926945923,
      "grad_norm": 0.6251009702682495,
      "learning_rate": 2.493250019285659e-05,
      "loss": 2.0876,
      "step": 11350
    },
    {
      "epoch": 0.8794260587826892,
      "grad_norm": 0.728777289390564,
      "learning_rate": 2.416107382550336e-05,
      "loss": 2.0663,
      "step": 11400
    },
    {
      "epoch": 0.8832831906194554,
      "grad_norm": 0.6011214852333069,
      "learning_rate": 2.3389647458150122e-05,
      "loss": 2.0829,
      "step": 11450
    },
    {
      "epoch": 0.8871403224562215,
      "grad_norm": 0.5396703481674194,
      "learning_rate": 2.2618221090796884e-05,
      "loss": 2.0775,
      "step": 11500
    },
    {
      "epoch": 0.8909974542929877,
      "grad_norm": 0.6149534583091736,
      "learning_rate": 2.1846794723443646e-05,
      "loss": 2.0717,
      "step": 11550
    },
    {
      "epoch": 0.8948545861297539,
      "grad_norm": 0.5635181665420532,
      "learning_rate": 2.1075368356090412e-05,
      "loss": 2.098,
      "step": 11600
    },
    {
      "epoch": 0.89871171796652,
      "grad_norm": 0.7201108336448669,
      "learning_rate": 2.031937051608424e-05,
      "loss": 2.0702,
      "step": 11650
    },
    {
      "epoch": 0.9025688498032862,
      "grad_norm": 0.531844973564148,
      "learning_rate": 1.9547944148731003e-05,
      "loss": 2.0891,
      "step": 11700
    },
    {
      "epoch": 0.9064259816400525,
      "grad_norm": 0.6450529098510742,
      "learning_rate": 1.8776517781377765e-05,
      "loss": 2.1052,
      "step": 11750
    },
    {
      "epoch": 0.9102831134768187,
      "grad_norm": 0.6212731599807739,
      "learning_rate": 1.8005091414024534e-05,
      "loss": 2.0988,
      "step": 11800
    },
    {
      "epoch": 0.9141402453135848,
      "grad_norm": 0.591266393661499,
      "learning_rate": 1.7233665046671297e-05,
      "loss": 2.117,
      "step": 11850
    },
    {
      "epoch": 0.917997377150351,
      "grad_norm": 0.5687267780303955,
      "learning_rate": 1.646223867931806e-05,
      "loss": 2.0915,
      "step": 11900
    },
    {
      "epoch": 0.9218545089871172,
      "grad_norm": 0.6902431845664978,
      "learning_rate": 1.569081231196482e-05,
      "loss": 2.1077,
      "step": 11950
    },
    {
      "epoch": 0.9257116408238834,
      "grad_norm": 0.5462523698806763,
      "learning_rate": 1.4919385944611589e-05,
      "loss": 2.0719,
      "step": 12000
    },
    {
      "epoch": 0.9295687726606495,
      "grad_norm": 0.5922566652297974,
      "learning_rate": 1.4147959577258351e-05,
      "loss": 2.0858,
      "step": 12050
    },
    {
      "epoch": 0.9334259044974157,
      "grad_norm": 0.7137166857719421,
      "learning_rate": 1.3376533209905115e-05,
      "loss": 2.086,
      "step": 12100
    },
    {
      "epoch": 0.9372830363341819,
      "grad_norm": 0.6403910517692566,
      "learning_rate": 1.2605106842551877e-05,
      "loss": 2.0748,
      "step": 12150
    },
    {
      "epoch": 0.941140168170948,
      "grad_norm": 0.6057830452919006,
      "learning_rate": 1.1833680475198643e-05,
      "loss": 2.098,
      "step": 12200
    },
    {
      "epoch": 0.9449973000077143,
      "grad_norm": 0.7351213097572327,
      "learning_rate": 1.1062254107845407e-05,
      "loss": 2.0861,
      "step": 12250
    },
    {
      "epoch": 0.9488544318444805,
      "grad_norm": 0.6367751955986023,
      "learning_rate": 1.0290827740492171e-05,
      "loss": 2.099,
      "step": 12300
    },
    {
      "epoch": 0.9527115636812467,
      "grad_norm": 0.6280555725097656,
      "learning_rate": 9.519401373138933e-06,
      "loss": 2.08,
      "step": 12350
    },
    {
      "epoch": 0.9565686955180128,
      "grad_norm": 0.5757070183753967,
      "learning_rate": 8.747975005785697e-06,
      "loss": 2.0889,
      "step": 12400
    },
    {
      "epoch": 0.960425827354779,
      "grad_norm": 0.5985075235366821,
      "learning_rate": 7.976548638432461e-06,
      "loss": 2.0672,
      "step": 12450
    },
    {
      "epoch": 0.9642829591915452,
      "grad_norm": 0.5748181343078613,
      "learning_rate": 7.205122271079226e-06,
      "loss": 2.0726,
      "step": 12500
    },
    {
      "epoch": 0.9681400910283113,
      "grad_norm": 0.5898797512054443,
      "learning_rate": 6.433695903725989e-06,
      "loss": 2.0962,
      "step": 12550
    },
    {
      "epoch": 0.9719972228650775,
      "grad_norm": 0.6469314694404602,
      "learning_rate": 5.662269536372753e-06,
      "loss": 2.0953,
      "step": 12600
    },
    {
      "epoch": 0.9758543547018437,
      "grad_norm": 0.6231309175491333,
      "learning_rate": 4.890843169019517e-06,
      "loss": 2.1033,
      "step": 12650
    },
    {
      "epoch": 0.9797114865386098,
      "grad_norm": 0.5992861986160278,
      "learning_rate": 4.1194168016662805e-06,
      "loss": 2.1101,
      "step": 12700
    },
    {
      "epoch": 0.9835686183753761,
      "grad_norm": 0.637352466583252,
      "learning_rate": 3.3479904343130445e-06,
      "loss": 2.0863,
      "step": 12750
    },
    {
      "epoch": 0.9874257502121423,
      "grad_norm": 0.5962965488433838,
      "learning_rate": 2.576564066959809e-06,
      "loss": 2.0747,
      "step": 12800
    },
    {
      "epoch": 0.9912828820489085,
      "grad_norm": 0.5530994534492493,
      "learning_rate": 1.8051376996065725e-06,
      "loss": 2.0887,
      "step": 12850
    },
    {
      "epoch": 0.9951400138856746,
      "grad_norm": 0.602669894695282,
      "learning_rate": 1.0337113322533365e-06,
      "loss": 2.0783,
      "step": 12900
    },
    {
      "epoch": 0.9989971457224408,
      "grad_norm": 0.6205094456672668,
      "learning_rate": 2.622849649001003e-07,
      "loss": 2.0382,
      "step": 12950
    }
  ],
  "logging_steps": 50,
  "max_steps": 12963,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.777274090899313e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
